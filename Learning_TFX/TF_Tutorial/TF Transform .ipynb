{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data with TensorFlow Transform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credits: [TFX Tutorials Transform](https://www.tensorflow.org/tfx/transform/get_started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-transform\n",
      "  Downloading tensorflow_transform-1.0.0-py3-none-any.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.6/dist-packages (from tensorflow-transform) (1.15.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-transform) (3.17.0)\n",
      "Collecting tfx-bsl<1.1.0,>=1.0.0\n",
      "  Downloading tfx_bsl-1.0.0-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<3,>=1\n",
      "  Downloading pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.7 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.16 in /usr/local/lib/python3.6/dist-packages (from tensorflow-transform) (1.19.5)\n",
      "Requirement already satisfied: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-transform) (2.5.0)\n",
      "Requirement already satisfied: absl-py<0.13,>=0.9 in /usr/local/lib/python3.6/dist-packages (from tensorflow-transform) (0.12.0)\n",
      "Collecting apache-beam[gcp]<3,>=2.29\n",
      "  Downloading apache_beam-2.29.0-cp36-cp36m-manylinux2010_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.1.0,>=1.0.0\n",
      "  Downloading tensorflow_metadata-1.0.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting google-api-python-client<2,>=1.7.11\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 75 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pandas<2,>=1.0\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15\n",
      "  Downloading tensorflow_serving_api-2.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (2.5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.1.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (2.5.0rc0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.34.1)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.1.2)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 686 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httplib2<0.18.0,>=0.8\n",
      "  Downloading httplib2-0.17.4-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 899 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.29->tensorflow-transform) (0.8)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.11.4-cp36-cp36m-manylinux2014_x86_64.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.29->tensorflow-transform) (2.25.1)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client<5,>=2.0.1\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2018.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 879 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.29->tensorflow-transform) (2.8.1)\n",
      "Collecting google-cloud-videointelligence<2,>=1.8.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_videointelligence-1.16.1-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 826 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n",
      "\u001b[K     |████████████████████████████████| 435 kB 799 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-datastore<2,>=1.7.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_datastore-1.15.3-py2.py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 940 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigquery-1.28.0-py2.py3-none-any.whl (187 kB)\n",
      "\u001b[K     |████████████████████████████████| 187 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-apitools<0.5.32,>=0.5.31; extra == \"gcp\"\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "\u001b[K     |████████████████████████████████| 173 kB 814 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-dlp<2,>=0.12.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_dlp-1.0.0-py2.py3-none-any.whl (169 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 169 kB 673 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<2,>=0.28.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-cloud-language<2,>=1.3.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_language-1.3.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 372 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<5,>=3.1.0; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.29->tensorflow-transform) (4.2.2)\n",
      "Collecting google-cloud-bigtable<2,>=0.31.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 425 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-pubsub<2,>=0.39.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_pubsub-1.7.0-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 771 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio-gcp<1,>=0.2.2; extra == \"gcp\"\n",
      "  Downloading grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Collecting google-cloud-spanner<2,>=1.13.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_spanner-1.19.1-py2.py3-none-any.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 933 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.18.0; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.29->tensorflow-transform) (1.30.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot<2,>=1.2->tensorflow-transform) (2.4.7)\n",
      "Collecting google-api-core<2dev,>=1.21.0\n",
      "  Downloading google_api_core-1.28.0-py2.py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 839 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (2.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (56.2.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.5.2)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (1.26.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (0.4.8)\n",
      "Collecting google-resumable-media<2.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-1.3.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fasteners>=0.14\n",
      "  Downloading fasteners-0.16-py2.py3-none-any.whl (28 kB)\n",
      "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
      "  Downloading grpc-google-iam-v1-0.12.3.tar.gz (13 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.11->tfx-bsl<1.1.0,>=1.0.0->tensorflow-transform) (20.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (4.0.1)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.2-cp36-cp36m-manylinux2014_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tensorflow-transform) (3.4.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.29->tensorflow-transform) (2.20)\n",
      "Building wheels for collected packages: crcmod, dill, avro-python3, future, google-apitools, docopt, grpc-google-iam-v1\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp36-cp36m-linux_x86_64.whl size=35382 sha256=f19060f70e5018624ef512a30aeeb28f71ec58f32ae7f76736f645cde00175e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/bb/07/adfb4ffd0aaace2022ea25c082a7cdc688b10d30e86d6d2fde\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78532 sha256=533aa5264778a624700de30ea61d8985f98cb39b7e99d776fd62a3b093504c6c\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=3fd6450a6cbefaae2e75bffd952a9a930d21ed084d74dc2843af333b95f21a50\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/08/0c/727bff8f20fedbdeb8a2c5214e460b214d41c10dc879cf6dac\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=8b476f2020a5c80e226fe9eb28d1f2a36cc3117ff72d8157c60be73b47954fb2\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131041 sha256=1d56ee6bfe9aa61b85dbbbd487a628510baa6443c8f90dad89a33d873a5bbf89\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/90/12/279bd3b09f3c9a4a0a5416b196eeec18ebc0e11d90ac342159\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=471df53770cecc59e22628c0df244e4dcae17682b21d3311cafa98cccb4e0861\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-py3-none-any.whl size=18499 sha256=a17cc7feaee93a09dc85ee043b0df9f3ca16d34451a51e184813e14e217c641d\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/65/cd/392da05e43270f143b6c5076ba88d39144abff586792593e7c\n",
      "Successfully built crcmod dill avro-python3 future google-apitools docopt grpc-google-iam-v1\n",
      "Installing collected packages: googleapis-common-protos, pytz, google-api-core, httplib2, google-auth-httplib2, uritemplate, google-api-python-client, pandas, pyarrow, tensorflow-serving-api, docopt, hdfs, fastavro, pydot, crcmod, dill, pymongo, avro-python3, future, oauth2client, google-cloud-videointelligence, google-cloud-vision, google-cloud-core, google-cloud-datastore, google-crc32c, google-resumable-media, google-cloud-bigquery, fasteners, google-apitools, google-cloud-dlp, google-cloud-language, grpc-google-iam-v1, google-cloud-bigtable, google-cloud-pubsub, grpcio-gcp, google-cloud-spanner, apache-beam, tensorflow-metadata, tfx-bsl, tensorflow-transform\n",
      "Successfully installed apache-beam-2.29.0 avro-python3-1.9.2.1 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.4.1 fasteners-0.16 future-0.18.2 google-api-core-1.28.0 google-api-python-client-1.12.8 google-apitools-0.5.31 google-auth-httplib2-0.1.0 google-cloud-bigquery-1.28.0 google-cloud-bigtable-1.7.0 google-cloud-core-1.6.0 google-cloud-datastore-1.15.3 google-cloud-dlp-1.0.0 google-cloud-language-1.3.0 google-cloud-pubsub-1.7.0 google-cloud-spanner-1.19.1 google-cloud-videointelligence-1.16.1 google-cloud-vision-1.0.0 google-crc32c-1.1.2 google-resumable-media-1.3.0 googleapis-common-protos-1.53.0 grpc-google-iam-v1-0.12.3 grpcio-gcp-0.2.2 hdfs-2.6.0 httplib2-0.17.4 oauth2client-4.1.3 pandas-1.1.5 pyarrow-2.0.0 pydot-1.4.2 pymongo-3.11.4 pytz-2021.1 tensorflow-metadata-1.0.0 tensorflow-serving-api-2.5.1 tensorflow-transform-1.0.0 tfx-bsl-1.0.0 uritemplate-3.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"Preprocessing function transforms each of three inputs in different ways\n",
    "    \n",
    "    Note:\n",
    "        Input `inputs` must be a dictionary of `Tensor` or `SparseTensor`\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary of `Tensor` or `SparseTensor` of the raw data\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary of `Tensor` or `SparseTensor` containing the transformed values\n",
    "    \"\"\"\n",
    "    x = inputs['x']\n",
    "    y = inputs['y']\n",
    "    s = inputs['s']\n",
    "    x_centered = x - tft.mean(x)\n",
    "    y_normalized = tft.scale_to_0_1(y)\n",
    "    s_integerized = tft.compute_and_apply_vocabulary(s)\n",
    "    x_centered_times_y_normalized = x_centered * y_normalized\n",
    "    \n",
    "    return {\n",
    "        'x_centered': x_centered,\n",
    "        'y_normalized': y_normalized,\n",
    "        'x_centered_times_y_normalized': x_centered_times_y_normalized,\n",
    "        's_integerized': s_integerized\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [\n",
    "    {'x': 1, 'y': 1, 's': 'hello'},\n",
    "    {'x': 2, 'y': 2, 's': 'world'},\n",
    "    {'x': 3, 'y': 3, 's': 'hello'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'x': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'y': tf.io.FixedLenFeature([], tf.int64),\n",
    "        's': tf.io.FixedLenFeature([], tf.string),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A tf.Transform function that required a temp dir was called but no temp dir was set.  To set a temp dir use the impl.Context context manager.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2682f9add10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m transformed_dataset, transform_fn = (\n\u001b[1;32m      4\u001b[0m (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n\u001b[0;32m----> 5\u001b[0;31m preprocessing_fn))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# transformed_data, transformed_metadata = transformed_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/transforms/ptransform.py\u001b[0m in \u001b[0;36m__ror__\u001b[0;34m(self, left, label)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mpvalueish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SetInputPValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeferred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transform, pvalueish, label)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalueish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0mpvalueish_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtype_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_type_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/runners/runner.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'apply_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    190\u001b[0m         'Execution of [%s] not implemented in runner %s.' % (transform, self))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/runners/runner.py\u001b[0m in \u001b[0;36mapply_PTransform\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply_PTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m# The base case of apply is to call the transform's expand.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m   def run_transform(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_transform/beam/impl.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;31m# e.g. caching the values of expensive computations done in AnalyzeDataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     transform_fn = (\n\u001b[0;32m-> 1303\u001b[0;31m         dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))\n\u001b[0m\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_use_deep_copy_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/transforms/ptransform.py\u001b[0m in \u001b[0;36m__ror__\u001b[0;34m(self, pvalueish, _unused)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ror__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__ror__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/transforms/ptransform.py\u001b[0m in \u001b[0;36m__ror__\u001b[0;34m(self, left, label)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mpvalueish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SetInputPValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeferred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transform, pvalueish, label)\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mold_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transform, pvalueish, label)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalueish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0mpvalueish_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtype_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_type_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/runners/runner.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'apply_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    190\u001b[0m         'Execution of [%s] not implemented in runner %s.' % (transform, self))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apache_beam/runners/runner.py\u001b[0m in \u001b[0;36mapply_PTransform\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply_PTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m# The base case of apply is to call the transform's expand.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m   def run_transform(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_transform/beam/impl.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m     result, cache = super(AnalyzeDataset, self).expand((input_values, None,\n\u001b[0;32m-> 1235\u001b[0;31m                                                         None, input_metadata))\n\u001b[0m\u001b[1;32m   1236\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_transform/beam/impl.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_adapter_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOriginalTypeSpecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mbase_temp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_base_temp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0;31m# TODO(b/149997088): Do not pass base_temp_dir here as this graph does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;31m# need to be serialized to SavedModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_transform/beam/context.py\u001b[0m in \u001b[0;36mcreate_base_temp_dir\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       raise ValueError(\n\u001b[0;32m--> 141\u001b[0;31m           \u001b[0;34m'A tf.Transform function that required a temp dir was called but no '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m           \u001b[0;34m'temp dir was set.  To set a temp dir use the impl.Context context '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m           'manager.')\n",
      "\u001b[0;31mValueError\u001b[0m: A tf.Transform function that required a temp dir was called but no temp dir was set.  To set a temp dir use the impl.Context context manager."
     ]
    }
   ],
   "source": [
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "transformed_dataset, transform_fn = (\n",
    "(raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n",
    "preprocessing_fn))\n",
    "# transformed_data, transformed_metadata = transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-442c2b25388b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed_data' is not defined"
     ]
    }
   ],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
